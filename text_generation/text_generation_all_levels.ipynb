{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t09eeeR5prIJ"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\ucshg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\ucshg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (0.12.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\ucshg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (12.0.0)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in c:\\users\\ucshg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\ucshg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\ucshg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\ucshg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\ucshg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.20.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\ucshg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.13.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\ucshg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in c:\\users\\ucshg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (0.23.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in c:\\users\\ucshg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\ucshg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in c:\\users\\ucshg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in c:\\users\\ucshg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\ucshg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (3.15.7)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in c:\\users\\ucshg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in c:\\users\\ucshg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\ucshg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\ucshg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (4.0.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\ucshg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\ucshg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.43.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\ucshg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\ucshg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\ucshg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\ucshg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\ucshg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.3.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\ucshg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\ucshg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (49.2.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\ucshg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\ucshg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\ucshg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\ucshg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\ucshg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\ucshg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\ucshg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.0.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ucshg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ucshg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ucshg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\ucshg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\ucshg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\ucshg\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\ucshg\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:39:05.728876Z",
     "iopub.status.busy": "2021-05-21T15:39:05.728288Z",
     "iopub.status.idle": "2021-05-21T15:39:12.383242Z",
     "shell.execute_reply": "2021-05-21T15:39:12.383622Z"
    },
    "id": "yG_n40gFzf9s"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:39:12.388508Z",
     "iopub.status.busy": "2021-05-21T15:39:12.387197Z",
     "iopub.status.idle": "2021-05-21T15:39:12.416004Z",
     "shell.execute_reply": "2021-05-21T15:39:12.416359Z"
    },
    "id": "pD_55cOxLkAb"
   },
   "outputs": [],
   "source": [
    "level = int(input(\"Enter the reading level :\\n 2 - BASIC\\n 1 - MID\\n 0 - COMPLEX\"))\n",
    "path_to_file = '../data/shakespeare.txt'#tf.keras.utils.get_file('story.train.2.txt','https://storage.cloud.google.com/cs229data/story.train.2.txt')\n",
    "if level == 0:\n",
    "    path_to_file = '../data/shakespeare.txt'#tf.keras.utils.get_file('story.train.2.txt','https://storage.cloud.google.com/cs229data/story.train.2.txt')\n",
    "elif level == 1:\n",
    "    path_to_file = '../data/shakespeare.txt'#tf.keras.utils.get_file('story.train.2.txt','https://storage.cloud.google.com/cs229data/story.train.2.txt')\n",
    "elif level == 2:\n",
    "    path_to_file = '../data/shakespeare.txt'#tf.keras.utils.get_file('story.train.2.txt','https://storage.cloud.google.com/cs229data/story.train.2.txt')\n",
    "else:\n",
    "    print(\"INVALID LEVEL CODE. GOING WITH THE DEFAULT (LEVEL 0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:39:12.420329Z",
     "iopub.status.busy": "2021-05-21T15:39:12.419756Z",
     "iopub.status.idle": "2021-05-21T15:39:12.423767Z",
     "shell.execute_reply": "2021-05-21T15:39:12.423338Z"
    },
    "id": "aavnuByVymwK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 121020 characters\n"
     ]
    }
   ],
   "source": [
    "# Read, then decode for py2 compat.\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "# length of text is the number of characters in it\n",
    "print(f'Length of text: {len(text)} characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:39:12.427458Z",
     "iopub.status.busy": "2021-05-21T15:39:12.426808Z",
     "iopub.status.idle": "2021-05-21T15:39:12.429139Z",
     "shell.execute_reply": "2021-05-21T15:39:12.429508Z"
    },
    "id": "Duhg9NrUymwO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACT I\n",
      "SCENE I. Venice. A street.\n",
      "Enter ANTONIO, SALARINO, and SALANIO\n",
      "ANTONIO\n",
      "In sooth, I know not why I am so sad:\n",
      "It wearies me; you say it wearies you;\n",
      "But how I caught it, found it, or came by it,\n",
      "What stuff 'tis made of, whereof it is bor\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the first 250 characters in text\n",
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:39:12.443162Z",
     "iopub.status.busy": "2021-05-21T15:39:12.442352Z",
     "iopub.status.idle": "2021-05-21T15:39:12.444795Z",
     "shell.execute_reply": "2021-05-21T15:39:12.445205Z"
    },
    "id": "IlCgQBRVymwR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 unique characters\n"
     ]
    }
   ],
   "source": [
    "# The unique characters in the file\n",
    "vocab = sorted(set(text))\n",
    "print(f'{len(vocab)} unique characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:39:13.132938Z",
     "iopub.status.busy": "2021-05-21T15:39:13.131972Z",
     "iopub.status.idle": "2021-05-21T15:39:13.416434Z",
     "shell.execute_reply": "2021-05-21T15:39:13.416805Z"
    },
    "id": "a86OoYtO01go"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_texts = ['abcdefg', 'xyz']\n",
    "\n",
    "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:39:13.421521Z",
     "iopub.status.busy": "2021-05-21T15:39:13.420624Z",
     "iopub.status.idle": "2021-05-21T15:39:13.431949Z",
     "shell.execute_reply": "2021-05-21T15:39:13.431508Z"
    },
    "id": "6GMlCe3qzaL9"
   },
   "outputs": [],
   "source": [
    "ids_from_chars = preprocessing.StringLookup(\n",
    "    vocabulary=list(vocab), mask_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:39:13.437328Z",
     "iopub.status.busy": "2021-05-21T15:39:13.436400Z",
     "iopub.status.idle": "2021-05-21T15:39:13.440578Z",
     "shell.execute_reply": "2021-05-21T15:39:13.440931Z"
    },
    "id": "WLv5Q_2TC2pc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = ids_from_chars(chars)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:39:13.447009Z",
     "iopub.status.busy": "2021-05-21T15:39:13.446149Z",
     "iopub.status.idle": "2021-05-21T15:39:13.449830Z",
     "shell.execute_reply": "2021-05-21T15:39:13.449359Z"
    },
    "id": "Wd2m3mqkDjRj"
   },
   "outputs": [],
   "source": [
    "chars_from_ids = tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:39:13.454099Z",
     "iopub.status.busy": "2021-05-21T15:39:13.453140Z",
     "iopub.status.idle": "2021-05-21T15:39:13.457289Z",
     "shell.execute_reply": "2021-05-21T15:39:13.457643Z"
    },
    "id": "c2GCh0ySD44s"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = chars_from_ids(ids)\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:39:13.462139Z",
     "iopub.status.busy": "2021-05-21T15:39:13.461192Z",
     "iopub.status.idle": "2021-05-21T15:39:13.472949Z",
     "shell.execute_reply": "2021-05-21T15:39:13.473309Z"
    },
    "id": "zxYI-PeltqKP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'abcdefg', b'xyz'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.reduce_join(chars, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:39:13.477304Z",
     "iopub.status.busy": "2021-05-21T15:39:13.476488Z",
     "iopub.status.idle": "2021-05-21T15:39:13.478890Z",
     "shell.execute_reply": "2021-05-21T15:39:13.478469Z"
    },
    "id": "w5apvBDn9Ind"
   },
   "outputs": [],
   "source": [
    "def text_from_ids(ids):\n",
    "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hgsVvVxnymwf"
   },
   "source": [
    "### Create training examples and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:39:13.484168Z",
     "iopub.status.busy": "2021-05-21T15:39:13.483339Z",
     "iopub.status.idle": "2021-05-21T15:39:13.949582Z",
     "shell.execute_reply": "2021-05-21T15:39:13.949126Z"
    },
    "id": "UopbsKi88tm5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(121020,), dtype=int64, numpy=array([12, 14, 31, ..., 60, 53, 59], dtype=int64)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
    "all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:39:13.954444Z",
     "iopub.status.busy": "2021-05-21T15:39:13.953552Z",
     "iopub.status.idle": "2021-05-21T15:39:13.955998Z",
     "shell.execute_reply": "2021-05-21T15:39:13.955543Z"
    },
    "id": "qmxrYDCTy-eL"
   },
   "outputs": [],
   "source": [
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:39:13.960409Z",
     "iopub.status.busy": "2021-05-21T15:39:13.959504Z",
     "iopub.status.idle": "2021-05-21T15:39:13.974499Z",
     "shell.execute_reply": "2021-05-21T15:39:13.974863Z"
    },
    "id": "cjH5v45-yqqH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "C\n",
      "T\n",
      " \n",
      "I\n",
      "\n",
      "\n",
      "\n",
      "S\n",
      "C\n",
      "E\n"
     ]
    }
   ],
   "source": [
    "for ids in ids_dataset.take(10):\n",
    "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:39:13.978806Z",
     "iopub.status.busy": "2021-05-21T15:39:13.977995Z",
     "iopub.status.idle": "2021-05-21T15:39:13.980050Z",
     "shell.execute_reply": "2021-05-21T15:39:13.980399Z"
    },
    "id": "C-G2oaTxy6km"
   },
   "outputs": [],
   "source": [
    "seq_length = 100\n",
    "examples_per_epoch = len(text)//(seq_length+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:39:13.985361Z",
     "iopub.status.busy": "2021-05-21T15:39:13.984423Z",
     "iopub.status.idle": "2021-05-21T15:39:13.994211Z",
     "shell.execute_reply": "2021-05-21T15:39:13.994562Z"
    },
    "id": "BpdjRO2CzOfZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'A' b'C' b'T' b' ' b'I' b'\\r' b'\\n' b'S' b'C' b'E' b'N' b'E' b' ' b'I'\n",
      " b'.' b' ' b'V' b'e' b'n' b'i' b'c' b'e' b'.' b' ' b'A' b' ' b's' b't'\n",
      " b'r' b'e' b'e' b't' b'.' b'\\r' b'\\n' b'E' b'n' b't' b'e' b'r' b' ' b'A'\n",
      " b'N' b'T' b'O' b'N' b'I' b'O' b',' b' ' b'S' b'A' b'L' b'A' b'R' b'I'\n",
      " b'N' b'O' b',' b' ' b'a' b'n' b'd' b' ' b'S' b'A' b'L' b'A' b'N' b'I'\n",
      " b'O' b'\\r' b'\\n' b'A' b'N' b'T' b'O' b'N' b'I' b'O' b'\\r' b'\\n' b'I' b'n'\n",
      " b' ' b's' b'o' b'o' b't' b'h' b',' b' ' b'I' b' ' b'k' b'n' b'o' b'w'\n",
      " b' ' b'n' b'o'], shape=(101,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for seq in sequences.take(1):\n",
    "  print(chars_from_ids(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:39:13.998892Z",
     "iopub.status.busy": "2021-05-21T15:39:13.997987Z",
     "iopub.status.idle": "2021-05-21T15:39:14.009585Z",
     "shell.execute_reply": "2021-05-21T15:39:14.009936Z"
    },
    "id": "QO32cMWu4a06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'ACT I\\r\\nSCENE I. Venice. A street.\\r\\nEnter ANTONIO, SALARINO, and SALANIO\\r\\nANTONIO\\r\\nIn sooth, I know no'\n",
      "b't why I am so sad:\\r\\nIt wearies me; you say it wearies you;\\r\\nBut how I caught it, found it, or came by'\n",
      "b\" it,\\r\\nWhat stuff 'tis made of, whereof it is born,\\r\\nI am to learn;\\r\\nAnd such a want-wit sadness makes\"\n",
      "b' of me,\\r\\nThat I have much ado to know myself.\\r\\nSALARINO\\r\\nYour mind is tossing on the ocean;\\r\\nThere, w'\n",
      "b'here your argosies with portly sail,\\r\\nLike signiors and rich burghers on the flood,\\r\\nOr, as it were, '\n"
     ]
    }
   ],
   "source": [
    "for seq in sequences.take(5):\n",
    "  print(text_from_ids(seq).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:39:14.014112Z",
     "iopub.status.busy": "2021-05-21T15:39:14.013321Z",
     "iopub.status.idle": "2021-05-21T15:39:14.015353Z",
     "shell.execute_reply": "2021-05-21T15:39:14.015722Z"
    },
    "id": "9NGu-FkO_kYU"
   },
   "outputs": [],
   "source": [
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:39:14.019967Z",
     "iopub.status.busy": "2021-05-21T15:39:14.019300Z",
     "iopub.status.idle": "2021-05-21T15:39:14.022336Z",
     "shell.execute_reply": "2021-05-21T15:39:14.021876Z"
    },
    "id": "WxbDTJTw5u_P"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
       " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_input_target(list(\"Tensorflow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:39:14.047572Z",
     "iopub.status.busy": "2021-05-21T15:39:14.026246Z",
     "iopub.status.idle": "2021-05-21T15:39:14.068996Z",
     "shell.execute_reply": "2021-05-21T15:39:14.068466Z"
    },
    "id": "B9iKPXkw5xwa"
   },
   "outputs": [],
   "source": [
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:39:14.073415Z",
     "iopub.status.busy": "2021-05-21T15:39:14.072811Z",
     "iopub.status.idle": "2021-05-21T15:39:14.094920Z",
     "shell.execute_reply": "2021-05-21T15:39:14.094369Z"
    },
    "id": "GNbw-iR0ymwj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input : b'ACT I\\r\\nSCENE I. Venice. A street.\\r\\nEnter ANTONIO, SALARINO, and SALANIO\\r\\nANTONIO\\r\\nIn sooth, I know n'\n",
      "Target: b'CT I\\r\\nSCENE I. Venice. A street.\\r\\nEnter ANTONIO, SALARINO, and SALANIO\\r\\nANTONIO\\r\\nIn sooth, I know no'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in dataset.take(1):\n",
    "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
    "    print(\"Target:\", text_from_ids(target_example).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJdfPmdqzf-R"
   },
   "source": [
    "### Create training batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:39:14.099225Z",
     "iopub.status.busy": "2021-05-21T15:39:14.098646Z",
     "iopub.status.idle": "2021-05-21T15:39:14.103411Z",
     "shell.execute_reply": "2021-05-21T15:39:14.103759Z"
    },
    "id": "p2pGotuNzf-S"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r6oUuElIMgVx"
   },
   "source": [
    "## Build The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:39:14.107715Z",
     "iopub.status.busy": "2021-05-21T15:39:14.107144Z",
     "iopub.status.idle": "2021-05-21T15:39:14.108916Z",
     "shell.execute_reply": "2021-05-21T15:39:14.109246Z"
    },
    "id": "zHT8cLh7EAsg"
   },
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:39:14.115265Z",
     "iopub.status.busy": "2021-05-21T15:39:14.114684Z",
     "iopub.status.idle": "2021-05-21T15:39:14.116921Z",
     "shell.execute_reply": "2021-05-21T15:39:14.116501Z"
    },
    "id": "wj8HQ2w8z4iO"
   },
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "    super().__init__(self)\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True)\n",
    "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "  def call(self, inputs, states=None, return_state=False, training=False):\n",
    "    x = inputs\n",
    "    x = self.embedding(x, training=training)\n",
    "    if states is None:\n",
    "      states = self.gru.get_initial_state(x)\n",
    "    x, states = self.gru(x, initial_state=states, training=training)\n",
    "    x = self.dense(x, training=training)\n",
    "\n",
    "    if return_state:\n",
    "      return x, states\n",
    "    else:\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:39:14.121700Z",
     "iopub.status.busy": "2021-05-21T15:39:14.121149Z",
     "iopub.status.idle": "2021-05-21T15:39:14.131846Z",
     "shell.execute_reply": "2021-05-21T15:39:14.131312Z"
    },
    "id": "IX58Xj9z47Aw"
   },
   "outputs": [],
   "source": [
    "model = MyModel(\n",
    "    # Be sure the vocabulary size matches the `StringLookup` layers.\n",
    "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ubPo0_9Prjb"
   },
   "source": [
    "## Try the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:39:14.136141Z",
     "iopub.status.busy": "2021-05-21T15:39:14.135567Z",
     "iopub.status.idle": "2021-05-21T15:39:18.353467Z",
     "shell.execute_reply": "2021-05-21T15:39:18.352940Z"
    },
    "id": "C-_70kKAPrPU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:39:18.358737Z",
     "iopub.status.busy": "2021-05-21T15:39:18.358125Z",
     "iopub.status.idle": "2021-05-21T15:39:18.361594Z",
     "shell.execute_reply": "2021-05-21T15:39:18.361954Z"
    },
    "id": "vPGmAAXmVLGC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       multiple                  16896     \n",
      "                                                                 \n",
      " gru (GRU)                   multiple                  3938304   \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  67650     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,022,850\n",
      "Trainable params: 4,022,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:39:18.366257Z",
     "iopub.status.busy": "2021-05-21T15:39:18.365603Z",
     "iopub.status.idle": "2021-05-21T15:39:18.368559Z",
     "shell.execute_reply": "2021-05-21T15:39:18.368909Z"
    },
    "id": "4V4MfFg0RQJg"
   },
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:39:18.373244Z",
     "iopub.status.busy": "2021-05-21T15:39:18.372607Z",
     "iopub.status.idle": "2021-05-21T15:39:18.375607Z",
     "shell.execute_reply": "2021-05-21T15:39:18.375990Z"
    },
    "id": "YqFMUQc_UFgM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([34, 15, 36, 37, 30,  2, 22, 28, 15, 29, 18, 22, 62, 59, 48, 30,  4,\n",
       "       15, 18, 33, 42, 34, 51, 16, 14, 42, 28, 23, 49, 40, 48, 39, 47, 42,\n",
       "       48, 34, 56, 52, 32, 18,  9,  4, 64, 28,  1, 30, 27, 25, 28, 23, 51,\n",
       "        3, 23, 32, 57,  4, 15, 23, 27, 33,  2, 61, 29, 31, 61, 24, 14, 58,\n",
       "       32, 47, 58, 19,  0, 30, 38,  9, 42, 28, 48, 60, 51, 49, 44, 44,  0,\n",
       "       11, 46, 17, 45, 26, 37,  6,  5, 15, 64, 25, 34, 11, 61, 53],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LfLtsP3mUhCG"
   },
   "source": [
    "Decode these to see the text predicted by this untrained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:39:18.379912Z",
     "iopub.status.busy": "2021-05-21T15:39:18.379267Z",
     "iopub.status.idle": "2021-05-21T15:39:18.384658Z",
     "shell.execute_reply": "2021-05-21T15:39:18.384233Z"
    },
    "id": "xWcFwPwLSo05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " b'ther\\r\\nLorenzo and his amorous Jessica:\\r\\nBesides, Antonio certified the duke\\r\\nThey were not with Bass'\n",
      "\n",
      "Next Char Predictions:\n",
      " b\"WDYZS\\rKQDRGKwtiS!DGVcWlECcQLjai]hciWqmUG:!yQ\\nSPNQLl LUr!DLPV\\rvRTvMCsUhsH[UNK]S[:cQiuljee[UNK]?gFfOZ,'DyNW?vn\"\n"
     ]
    }
   ],
   "source": [
    "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
    "print()\n",
    "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LJL0Q0YPY6Ee"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:39:18.388618Z",
     "iopub.status.busy": "2021-05-21T15:39:18.388049Z",
     "iopub.status.idle": "2021-05-21T15:39:18.390700Z",
     "shell.execute_reply": "2021-05-21T15:39:18.390253Z"
    },
    "id": "ZOeWdgxNFDXq"
   },
   "outputs": [],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:39:18.394850Z",
     "iopub.status.busy": "2021-05-21T15:39:18.394279Z",
     "iopub.status.idle": "2021-05-21T15:39:18.400560Z",
     "shell.execute_reply": "2021-05-21T15:39:18.400912Z"
    },
    "id": "4HrXTACTdzY-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
      "Mean loss:         4.189276\n"
     ]
    }
   ],
   "source": [
    "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
    "mean_loss = example_batch_loss.numpy().mean()\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"Mean loss:        \", mean_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:39:18.404569Z",
     "iopub.status.busy": "2021-05-21T15:39:18.403958Z",
     "iopub.status.idle": "2021-05-21T15:39:18.407838Z",
     "shell.execute_reply": "2021-05-21T15:39:18.408204Z"
    },
    "id": "MAJfS5YoFiHf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65.97502"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.exp(mean_loss).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:39:18.415050Z",
     "iopub.status.busy": "2021-05-21T15:39:18.414491Z",
     "iopub.status.idle": "2021-05-21T15:39:18.419720Z",
     "shell.execute_reply": "2021-05-21T15:39:18.420069Z"
    },
    "id": "DDl1_Een6rL0"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ieSJdchZggUj"
   },
   "source": [
    "### Configure checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:39:18.423963Z",
     "iopub.status.busy": "2021-05-21T15:39:18.423405Z",
     "iopub.status.idle": "2021-05-21T15:39:18.426007Z",
     "shell.execute_reply": "2021-05-21T15:39:18.425539Z"
    },
    "id": "W6fWTriUZP-n"
   },
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Ky3F_BhgkTW"
   },
   "source": [
    "### Execute the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:39:18.429472Z",
     "iopub.status.busy": "2021-05-21T15:39:18.428913Z",
     "iopub.status.idle": "2021-05-21T15:39:18.431380Z",
     "shell.execute_reply": "2021-05-21T15:39:18.430936Z"
    },
    "id": "7yGBE2zxMMHs"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "if level == 0:\n",
    "    EPOCHS = 30\n",
    "elif level == 1:\n",
    "    EPOCHS = 150\n",
    "elif level == 2:\n",
    "    EPOCHS = 200\n",
    "else:\n",
    "    EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:39:18.435162Z",
     "iopub.status.busy": "2021-05-21T15:39:18.434589Z",
     "iopub.status.idle": "2021-05-21T15:41:07.648325Z",
     "shell.execute_reply": "2021-05-21T15:41:07.647733Z"
    },
    "id": "UK-hmKjYVoll"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "18/18 [==============================] - 76s 4s/step - loss: 4.1621\n",
      "Epoch 2/150\n",
      "18/18 [==============================] - 72s 4s/step - loss: 3.3218\n",
      "Epoch 3/150\n",
      "18/18 [==============================] - 76s 4s/step - loss: 2.8893\n",
      "Epoch 4/150\n",
      "18/18 [==============================] - 77s 4s/step - loss: 2.5759\n",
      "Epoch 5/150\n",
      "18/18 [==============================] - 77s 4s/step - loss: 2.3992\n",
      "Epoch 6/150\n",
      "18/18 [==============================] - 77s 4s/step - loss: 2.3044\n",
      "Epoch 7/150\n",
      "18/18 [==============================] - 75s 4s/step - loss: 2.2360\n",
      "Epoch 8/150\n",
      "18/18 [==============================] - 68s 4s/step - loss: 2.1751\n",
      "Epoch 9/150\n",
      "18/18 [==============================] - 78s 4s/step - loss: 2.1182\n",
      "Epoch 10/150\n",
      "18/18 [==============================] - 59s 3s/step - loss: 2.0628\n",
      "Epoch 11/150\n",
      "18/18 [==============================] - 71s 4s/step - loss: 2.0038\n",
      "Epoch 12/150\n",
      "18/18 [==============================] - 65s 4s/step - loss: 1.9485\n",
      "Epoch 13/150\n",
      "18/18 [==============================] - 61s 3s/step - loss: 1.8977\n",
      "Epoch 14/150\n",
      "18/18 [==============================] - 64s 4s/step - loss: 1.8456\n",
      "Epoch 15/150\n",
      "18/18 [==============================] - 60s 3s/step - loss: 1.7990\n",
      "Epoch 16/150\n",
      "18/18 [==============================] - 63s 3s/step - loss: 1.7536\n",
      "Epoch 17/150\n",
      "18/18 [==============================] - 59s 3s/step - loss: 1.7103\n",
      "Epoch 18/150\n",
      "18/18 [==============================] - 63s 3s/step - loss: 1.6658\n",
      "Epoch 19/150\n",
      "18/18 [==============================] - 66s 4s/step - loss: 1.6312\n",
      "Epoch 20/150\n",
      "18/18 [==============================] - 62s 3s/step - loss: 1.5912\n",
      "Epoch 21/150\n",
      "18/18 [==============================] - 75s 4s/step - loss: 1.5545\n",
      "Epoch 22/150\n",
      "18/18 [==============================] - 67s 4s/step - loss: 1.5158\n",
      "Epoch 23/150\n",
      "18/18 [==============================] - 63s 3s/step - loss: 1.4790\n",
      "Epoch 24/150\n",
      "18/18 [==============================] - 62s 3s/step - loss: 1.4403\n",
      "Epoch 25/150\n",
      "18/18 [==============================] - 62s 3s/step - loss: 1.4028\n",
      "Epoch 26/150\n",
      "18/18 [==============================] - 62s 3s/step - loss: 1.3667\n",
      "Epoch 27/150\n",
      "18/18 [==============================] - 62s 3s/step - loss: 1.3248\n",
      "Epoch 28/150\n",
      "18/18 [==============================] - 66s 4s/step - loss: 1.2877\n",
      "Epoch 29/150\n",
      "18/18 [==============================] - 63s 3s/step - loss: 1.2487\n",
      "Epoch 30/150\n",
      "18/18 [==============================] - 69s 4s/step - loss: 1.2077\n",
      "Epoch 31/150\n",
      "18/18 [==============================] - 70s 4s/step - loss: 1.1671\n",
      "Epoch 32/150\n",
      "18/18 [==============================] - 66s 4s/step - loss: 1.1218\n",
      "Epoch 33/150\n",
      "18/18 [==============================] - 67s 4s/step - loss: 1.0724\n",
      "Epoch 34/150\n",
      "18/18 [==============================] - 73s 4s/step - loss: 1.0292\n",
      "Epoch 35/150\n",
      "18/18 [==============================] - 68s 4s/step - loss: 0.9758\n",
      "Epoch 36/150\n",
      "18/18 [==============================] - 68s 4s/step - loss: 0.9268\n",
      "Epoch 37/150\n",
      "18/18 [==============================] - 72s 4s/step - loss: 0.8718\n",
      "Epoch 38/150\n",
      "18/18 [==============================] - 67s 4s/step - loss: 0.8181\n",
      "Epoch 39/150\n",
      "18/18 [==============================] - 67s 4s/step - loss: 0.7562\n",
      "Epoch 40/150\n",
      "18/18 [==============================] - 62s 3s/step - loss: 0.6962\n",
      "Epoch 41/150\n",
      "18/18 [==============================] - 66s 4s/step - loss: 0.6431\n",
      "Epoch 42/150\n",
      "18/18 [==============================] - 70s 4s/step - loss: 0.5843\n",
      "Epoch 43/150\n",
      "18/18 [==============================] - 74s 4s/step - loss: 0.5260\n",
      "Epoch 44/150\n",
      "18/18 [==============================] - 73s 4s/step - loss: 0.4716\n",
      "Epoch 45/150\n",
      "18/18 [==============================] - 74s 4s/step - loss: 0.4178\n",
      "Epoch 46/150\n",
      "18/18 [==============================] - 74s 4s/step - loss: 0.3672\n",
      "Epoch 47/150\n",
      "18/18 [==============================] - 71s 4s/step - loss: 0.3224\n",
      "Epoch 48/150\n",
      "18/18 [==============================] - 71s 4s/step - loss: 0.2845\n",
      "Epoch 49/150\n",
      "18/18 [==============================] - 74s 4s/step - loss: 0.2488\n",
      "Epoch 50/150\n",
      "18/18 [==============================] - 76s 4s/step - loss: 0.2179\n",
      "Epoch 51/150\n",
      "18/18 [==============================] - 73s 4s/step - loss: 0.1930\n",
      "Epoch 52/150\n",
      "18/18 [==============================] - 67s 4s/step - loss: 0.1711\n",
      "Epoch 53/150\n",
      "18/18 [==============================] - 73s 4s/step - loss: 0.1534\n",
      "Epoch 54/150\n",
      "18/18 [==============================] - 71s 4s/step - loss: 0.1385\n",
      "Epoch 55/150\n",
      "18/18 [==============================] - 61s 3s/step - loss: 0.1266\n",
      "Epoch 56/150\n",
      "18/18 [==============================] - 77s 4s/step - loss: 0.1174\n",
      "Epoch 57/150\n",
      "18/18 [==============================] - 70s 4s/step - loss: 0.1085\n",
      "Epoch 58/150\n",
      "18/18 [==============================] - 76s 4s/step - loss: 0.1008\n",
      "Epoch 59/150\n",
      "18/18 [==============================] - 72s 4s/step - loss: 0.0939\n",
      "Epoch 60/150\n",
      "18/18 [==============================] - 76s 4s/step - loss: 0.0889\n",
      "Epoch 61/150\n",
      "18/18 [==============================] - 78s 4s/step - loss: 0.0843\n",
      "Epoch 62/150\n",
      "18/18 [==============================] - 68s 4s/step - loss: 0.0807\n",
      "Epoch 63/150\n",
      "18/18 [==============================] - 72s 4s/step - loss: 0.0771\n",
      "Epoch 64/150\n",
      "18/18 [==============================] - 67s 4s/step - loss: 0.0740\n",
      "Epoch 65/150\n",
      "18/18 [==============================] - 67s 4s/step - loss: 0.0715\n",
      "Epoch 66/150\n",
      "18/18 [==============================] - 63s 3s/step - loss: 0.0692\n",
      "Epoch 67/150\n",
      "18/18 [==============================] - 63s 3s/step - loss: 0.0676\n",
      "Epoch 68/150\n",
      "18/18 [==============================] - 65s 4s/step - loss: 0.0654\n",
      "Epoch 69/150\n",
      "18/18 [==============================] - 59s 3s/step - loss: 0.0643\n",
      "Epoch 70/150\n",
      "18/18 [==============================] - 68s 4s/step - loss: 0.0634\n",
      "Epoch 71/150\n",
      "18/18 [==============================] - 64s 4s/step - loss: 0.0620\n",
      "Epoch 72/150\n",
      "18/18 [==============================] - 67s 4s/step - loss: 0.0612\n",
      "Epoch 73/150\n",
      "18/18 [==============================] - 69s 4s/step - loss: 0.0600\n",
      "Epoch 74/150\n",
      "18/18 [==============================] - 71s 4s/step - loss: 0.0594\n",
      "Epoch 75/150\n",
      "18/18 [==============================] - 67s 4s/step - loss: 0.0583\n",
      "Epoch 76/150\n",
      "18/18 [==============================] - 67s 4s/step - loss: 0.0576\n",
      "Epoch 77/150\n",
      "18/18 [==============================] - 66s 4s/step - loss: 0.0569\n",
      "Epoch 78/150\n",
      "18/18 [==============================] - 64s 4s/step - loss: 0.0562\n",
      "Epoch 79/150\n",
      "18/18 [==============================] - 62s 3s/step - loss: 0.0555\n",
      "Epoch 80/150\n",
      "18/18 [==============================] - 64s 4s/step - loss: 0.0552\n",
      "Epoch 81/150\n",
      "18/18 [==============================] - 79s 4s/step - loss: 0.0548\n",
      "Epoch 82/150\n",
      "18/18 [==============================] - 69s 4s/step - loss: 0.0545\n",
      "Epoch 83/150\n",
      "18/18 [==============================] - 67s 4s/step - loss: 0.0538\n",
      "Epoch 84/150\n",
      "18/18 [==============================] - 63s 3s/step - loss: 0.0535\n",
      "Epoch 85/150\n",
      "18/18 [==============================] - 69s 4s/step - loss: 0.0531\n",
      "Epoch 86/150\n",
      "18/18 [==============================] - 62s 3s/step - loss: 0.0528\n",
      "Epoch 87/150\n",
      "18/18 [==============================] - 60s 3s/step - loss: 0.0529\n",
      "Epoch 88/150\n",
      "18/18 [==============================] - 58s 3s/step - loss: 0.0526\n",
      "Epoch 89/150\n",
      "18/18 [==============================] - 64s 4s/step - loss: 0.0525\n",
      "Epoch 90/150\n",
      "18/18 [==============================] - 57s 3s/step - loss: 0.0522\n",
      "Epoch 91/150\n",
      "18/18 [==============================] - 58s 3s/step - loss: 0.0519\n",
      "Epoch 92/150\n",
      "18/18 [==============================] - 59s 3s/step - loss: 0.0530\n",
      "Epoch 93/150\n",
      "18/18 [==============================] - 59s 3s/step - loss: 0.0549\n",
      "Epoch 94/150\n",
      "18/18 [==============================] - 54s 3s/step - loss: 0.0568\n",
      "Epoch 95/150\n",
      "18/18 [==============================] - 54s 3s/step - loss: 0.0630\n",
      "Epoch 96/150\n",
      "18/18 [==============================] - 66s 4s/step - loss: 0.0801\n",
      "Epoch 97/150\n",
      "18/18 [==============================] - 59s 3s/step - loss: 0.1165\n",
      "Epoch 98/150\n",
      "18/18 [==============================] - 58s 3s/step - loss: 0.1580\n",
      "Epoch 99/150\n",
      "18/18 [==============================] - 59s 3s/step - loss: 0.1610\n",
      "Epoch 100/150\n",
      "18/18 [==============================] - 64s 4s/step - loss: 0.1326\n",
      "Epoch 101/150\n",
      "18/18 [==============================] - 62s 3s/step - loss: 0.1021\n",
      "Epoch 102/150\n",
      "18/18 [==============================] - 61s 3s/step - loss: 0.0768\n",
      "Epoch 103/150\n",
      "18/18 [==============================] - 60s 3s/step - loss: 0.0629\n",
      "Epoch 104/150\n",
      "18/18 [==============================] - 60s 3s/step - loss: 0.0559\n",
      "Epoch 105/150\n",
      "18/18 [==============================] - 61s 3s/step - loss: 0.0525\n",
      "Epoch 106/150\n",
      "18/18 [==============================] - 65s 4s/step - loss: 0.0509\n",
      "Epoch 107/150\n",
      "18/18 [==============================] - 61s 3s/step - loss: 0.0498\n",
      "Epoch 108/150\n",
      "18/18 [==============================] - 61s 3s/step - loss: 0.0492\n",
      "Epoch 109/150\n",
      "18/18 [==============================] - 61s 3s/step - loss: 0.0486\n",
      "Epoch 110/150\n",
      "18/18 [==============================] - 58s 3s/step - loss: 0.0483\n",
      "Epoch 111/150\n",
      "18/18 [==============================] - 59s 3s/step - loss: 0.0478\n",
      "Epoch 112/150\n",
      "18/18 [==============================] - 66s 4s/step - loss: 0.0477\n",
      "Epoch 113/150\n",
      "18/18 [==============================] - 64s 4s/step - loss: 0.0476\n",
      "Epoch 114/150\n",
      "18/18 [==============================] - 275s 16s/step - loss: 0.0472\n",
      "Epoch 115/150\n",
      "18/18 [==============================] - 69s 4s/step - loss: 0.0475\n",
      "Epoch 116/150\n",
      "18/18 [==============================] - 67s 4s/step - loss: 0.0472\n",
      "Epoch 117/150\n",
      "18/18 [==============================] - 67s 4s/step - loss: 0.0468\n",
      "Epoch 118/150\n",
      "18/18 [==============================] - 66s 4s/step - loss: 0.0470\n",
      "Epoch 119/150\n",
      "18/18 [==============================] - 62s 3s/step - loss: 0.0471\n",
      "Epoch 120/150\n",
      "18/18 [==============================] - 58s 3s/step - loss: 0.0470\n",
      "Epoch 121/150\n",
      "18/18 [==============================] - 61s 3s/step - loss: 0.0466\n",
      "Epoch 122/150\n",
      "18/18 [==============================] - 60s 3s/step - loss: 0.0466\n",
      "Epoch 123/150\n",
      "18/18 [==============================] - 61s 3s/step - loss: 0.0468\n",
      "Epoch 124/150\n",
      "18/18 [==============================] - 63s 3s/step - loss: 0.0463\n",
      "Epoch 125/150\n",
      "18/18 [==============================] - 67s 4s/step - loss: 0.0466\n",
      "Epoch 126/150\n",
      "18/18 [==============================] - 60s 3s/step - loss: 0.0465\n",
      "Epoch 127/150\n",
      "18/18 [==============================] - 63s 3s/step - loss: 0.0463\n",
      "Epoch 128/150\n",
      "18/18 [==============================] - 62s 3s/step - loss: 0.0462\n",
      "Epoch 129/150\n",
      "18/18 [==============================] - 63s 3s/step - loss: 0.0461\n",
      "Epoch 130/150\n",
      "18/18 [==============================] - 62s 3s/step - loss: 0.0463\n",
      "Epoch 131/150\n",
      "18/18 [==============================] - 64s 4s/step - loss: 0.0460\n",
      "Epoch 132/150\n",
      "18/18 [==============================] - 63s 3s/step - loss: 0.0462\n",
      "Epoch 133/150\n",
      "18/18 [==============================] - 63s 3s/step - loss: 0.0464\n",
      "Epoch 134/150\n",
      "18/18 [==============================] - 61s 3s/step - loss: 0.0460\n",
      "Epoch 135/150\n",
      "18/18 [==============================] - 64s 4s/step - loss: 0.0461\n",
      "Epoch 136/150\n",
      "18/18 [==============================] - 173s 10s/step - loss: 0.0459\n",
      "Epoch 137/150\n",
      "18/18 [==============================] - 64s 4s/step - loss: 0.0460\n",
      "Epoch 138/150\n",
      "18/18 [==============================] - 63s 4s/step - loss: 0.0457\n",
      "Epoch 139/150\n",
      "18/18 [==============================] - 63s 3s/step - loss: 0.0459\n",
      "Epoch 140/150\n",
      "18/18 [==============================] - 64s 4s/step - loss: 0.0461\n",
      "Epoch 141/150\n",
      "18/18 [==============================] - 61s 3s/step - loss: 0.0458\n",
      "Epoch 142/150\n",
      "18/18 [==============================] - 61s 3s/step - loss: 0.0457\n",
      "Epoch 143/150\n",
      "18/18 [==============================] - 64s 4s/step - loss: 0.0460\n",
      "Epoch 144/150\n",
      "18/18 [==============================] - 66s 4s/step - loss: 0.0460\n",
      "Epoch 145/150\n",
      "18/18 [==============================] - 60s 3s/step - loss: 0.0459\n",
      "Epoch 146/150\n",
      "18/18 [==============================] - 60s 3s/step - loss: 0.0458\n",
      "Epoch 147/150\n",
      "18/18 [==============================] - 63s 3s/step - loss: 0.0458\n",
      "Epoch 148/150\n",
      "18/18 [==============================] - 62s 3s/step - loss: 0.0456\n",
      "Epoch 149/150\n",
      "18/18 [==============================] - 63s 3s/step - loss: 0.0455\n",
      "Epoch 150/150\n",
      "18/18 [==============================] - 63s 3s/step - loss: 0.0458\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKkD5M6eoSiN"
   },
   "source": [
    "## Generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if level == 0:\n",
    "#     model.save('level_0.model')\n",
    "# elif level == 1:\n",
    "#     model.save('level_1.model')\n",
    "# elif level == 2:\n",
    "#     model.save('level_2.model')\n",
    "# else:\n",
    "#     model.save('level_0.model')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if level == 0:\n",
    "#     model = tf.keras.models.load_model('level_0.model', custom_objects=None, compile=True)\n",
    "# elif level == 1:\n",
    "#     model = tf.keras.models.load_model('level_1.model', custom_objects=None, compile=True)\n",
    "# elif level == 2:\n",
    "#     model = tf.keras.models.load_model('level_2.model', custom_objects=None, compile=True)\n",
    "# else:\n",
    "#     model = tf.keras.models.load_model('level_0.model', custom_objects=None, compile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:41:07.657627Z",
     "iopub.status.busy": "2021-05-21T15:41:07.656671Z",
     "iopub.status.idle": "2021-05-21T15:41:07.659150Z",
     "shell.execute_reply": "2021-05-21T15:41:07.658631Z"
    },
    "id": "iSBU1tHmlUSs"
   },
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
    "    super().__init__()\n",
    "    self.temperature = temperature\n",
    "    self.model = model\n",
    "    self.chars_from_ids = chars_from_ids\n",
    "    self.ids_from_chars = ids_from_chars\n",
    "\n",
    "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
    "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
    "    sparse_mask = tf.SparseTensor(\n",
    "        # Put a -inf at each bad index.\n",
    "        values=[-float('inf')]*len(skip_ids),\n",
    "        indices=skip_ids,\n",
    "        # Match the shape to the vocabulary\n",
    "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
    "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "  @tf.function\n",
    "  def generate_one_step(self, inputs, states=None):\n",
    "    # Convert strings to token IDs.\n",
    "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "    # Run the model.\n",
    "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
    "                                          return_state=True)\n",
    "    # Only use the last prediction.\n",
    "    predicted_logits = predicted_logits[:, -1, :]\n",
    "    predicted_logits = predicted_logits/self.temperature\n",
    "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
    "    predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "    # Sample the output logits to generate token IDs.\n",
    "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "    # Convert from token ids to characters\n",
    "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "    # Return the characters and model state.\n",
    "    return predicted_chars, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:41:07.664421Z",
     "iopub.status.busy": "2021-05-21T15:41:07.663498Z",
     "iopub.status.idle": "2021-05-21T15:41:07.670551Z",
     "shell.execute_reply": "2021-05-21T15:41:07.670099Z"
    },
    "id": "fqMOuDutnOxK"
   },
   "outputs": [],
   "source": [
    "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:41:07.676784Z",
     "iopub.status.busy": "2021-05-21T15:41:07.675916Z",
     "iopub.status.idle": "2021-05-21T15:41:10.098880Z",
     "shell.execute_reply": "2021-05-21T15:41:10.099272Z"
    },
    "id": "ST7PSyk9t1mT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO: fie, fie!\n",
      "SALARINO\n",
      "Not in love neither? If I do know your tongue.\n",
      "LORENZO\n",
      "Lorenzo, and thy love.\n",
      "JESSICA\n",
      "Nay, but ask me, when I thought\n",
      "With the doctor a rest and lought his own intortured\n",
      "Dot your dost bear unto the praising of myself;\n",
      "Therefore no more of it: hear other things.\n",
      "Lorenzo, I commit into your fair heappien\n",
      "His tedilound me, I must go with me; peruse this as thou goest:\n",
      "Fair Jessica shall be my torch-beare r.\n",
      "Exeunt\n",
      "\n",
      "SCENE II. Belmont. A room in PORTIA'S house.\n",
      "Enter NERISSA with a Servitor\n",
      "NERISSA\n",
      "Quir, I rear duscenish of cornets. Enter the PRINCE OF MOROCCO and his train; PORTIA, NERISSA, and others attending\n",
      "part of our hisbees of brothes of sucher,\n",
      "us the fery draw contentaning\n",
      "eye our absine a daughter: twenty merchants,\n",
      "The duke himself, and the magnificoes\n",
      "That did sevent turn you merry.\n",
      "ANTONIO\n",
      "I not do but note a wild and water-right:\n",
      "I have sent twenty out to seek for you.\n",
      "GRATIANO\n",
      "I am glad on't: I desire no more than I had,\n",
      "Your \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 8.011064767837524\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['ROMEO:'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:41:10.105268Z",
     "iopub.status.busy": "2021-05-21T15:41:10.104709Z",
     "iopub.status.idle": "2021-05-21T15:41:12.318073Z",
     "shell.execute_reply": "2021-05-21T15:41:12.318494Z"
    },
    "id": "ZkLu7Y8UCMT7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b\"ROMEO: There, then, let me provert with him\\r\\nTo one that would have him help to waste\\r\\nThan is thy strange apparent cruelty;\\r\\nAnd where thou now exact'st the penalty,\\r\\nWhich here appeareth due upon the bond.\\r\\nSHYLOCK\\r\\n'Tis very wleng Lord, what have at earing the\\r\\nmesty taken fren to becamed\\r\\nTo Christian in oath: so for that I choose that the\\r\\ngrace of Lord Bassanio and myself meantime\\r\\nWill live as maids and widows. Come, away!\\r\\nFor we must measure twenty miles to-day.\\r\\nExeunt\\r\\n\\r\\nSCENE V. The same. Before SHYLOCK'S house.\\r\\nEnter SHYLOCK and LAUNCELOT\\r\\nSHYLOCK\\r\\nWell, thou shalt see, there is something else.\\r\\nThis bond doth give thee here no jow his mere\\r\\nCannot in prayith, for if me Tord.\\r\\nNERISSA\\r\\nWho, if he break, thou mayst with better face\\r\\nExact the penalty. He will leave you then thirk--\\r\\nGRATIANO\\r\\nA second Daniel, a Daniel, Jew!\\r\\nNow, infidel, I have you on the hip.\\r\\nPORTIA\\r\\nWhy doth the greater ngrownight let him look to his bond: he was\\r\\nwont to lenel rim, I pray you,\\r\\nOr you repay\"\n",
      " b\"ROMEO: By Genoa,--reason a Jew, if I serve the Jew any longer.\\r\\nEnter BASSANIO, with LEONARDO and other followers\\r\\n\\r\\nBASSANIO\\r\\nWhy dost thou whet thy knife so earnestly?\\r\\nSHYLOCK\\r\\nTo bait fish withal: if it will feed my revenge.\\r\\nPORTIA\\r\\nTo their right praise and true perfection!\\r\\nPeace, ho! the moon sleep;\\r\\nAnd therefore, like herself, wise, fair and true,\\r\\nShall she be place May wrought in his behalf,\\r\\nThe third possessor; ay, he was the third--\\r\\nANTONIO\\r\\nWho's doubt, I gall the Jew doth then showsl here\\r\\nHave power to bid entreat the vrien.\\r\\nSHYLOCK\\r\\nO noble judge! O excellent young man!\\r\\nPORTIA\\r\\nFor the intent and purpose of these many friends,\\r\\nI swear to search and raughter course\\r\\nTo stake with mire you ted mile own protection.\\r\\nGRATIANO\\r\\nWell, do you see ba!\\r\\nHere's the mo, Bassanio and A trickless of confistion\\r\\nHe vely true! Give them him without a fee.\\r\\nThere do I give to you and Jessica\\r\\nIn place of Lord Bassanio and myself meantime\\r\\nWill live as maids and widows. Come, away!\\r\\nFo\"\n",
      " b\"ROMEO: fie, fie, Gratiano! where are all the rest?\\r\\n'Tis nine that which I neigh of such a night\\r\\nTroilus methinks mounted the Trocks\\r\\nWhich make such wanton gambols with the wind,\\r\\nUpon supposed fairness, often known\\r\\nTo be the day come, I should wish it dark,\\r\\nThat I were couche him, what he would net right\\r\\nthan there is between red wine and rhenish. But\\r\\ntell us, do you hear whether Antonio hath\\r\\na ship of rich lading wrecked on the narrow seas;\\r\\nthe Goodwins, I think they come, but our succesisice\\r\\nIs may is a wise father that knows his\\r\\nown child. Well, old man, I will thithers\\r\\nof marriage: therefore be well advised\\r\\nHow you do leave me to mine own protection.\\r\\nGRATIANO\\r\\nWell, do you not know me, father?\\r\\nGOBBO\\r\\nAlack the day, I know you not, young gentleman:\\r\\nbut, I pray you, which is the wayst impele\\r\\nThat indirectly and directly too\\r\\nThou hast contrived against your wife's commandment.\\r\\nBASSANIO\\r\\nGo, Gratiano, run and overtake him;\\r\\nGive here a listle wrong, doth cause me,\\r\\nTherefo\"\n",
      " b\"ROMEO: This was a venture, sir, that Jacob served for;\\r\\nA thing not in his power to be abrided of dressing:\\r\\nI will ever be your head:\\r\\nSo be gone: you are not merry: and 'twere as easy\\r\\nFor you to laugh and lead it, praying nory bound in all\\r\\nbut a hold you is a dogat henlies:'\\r\\nThe suit is forfeit of my house\\r\\nUntil my lord's return: for mine own part,\\r\\nI have tow upon his death,\\r\\nNor will not. Come, bring me unto my chance.\\r\\nPORTIA\\r\\nFirst, forward to the templies\\r\\nGod grant me two things, I pray you,\\r\\nNo more of them in the strength of your displeasure.\\r\\nPORTIA\\r\\nTherefore prepare thee to cut off the flesh.\\r\\nShed thou no blood, nor cut thou less nor more\\r\\nBut she may learn; happily to be about it with much conscience,\\r\\nA pound of flesh, to be by him cut off\\r\\nNearest the merchant's heart. Be merciful:\\r\\nTake this offer, then; pay the bond thrice\\r\\nAnd let the Christian such a bond for me:\\r\\nI'll have my bond; and therefore speak no more.\\r\\nI'll not now: for in companions\\r\\nThat dochou come the r\"\n",
      " b\"ROMEO: fie!\\r\\nSALARINO\\r\\nNot in love neither? If I do be done,\\r\\nBut mercy is above this sceptred bit her\\r\\nPortiand an honest woman of her word.\\r\\nSALANIO\\r\\nI would she were as lying bot, that if I should bread not take\\r\\nBy bay first to groals.\\r\\nBut who comes here? Lorenzo and his infidel? What,\\r\\nand my out propoRed cettimidg in your brhast dort\\r\\nThere you shall find three of your argosies\\r\\nAnd the virgin sere bit dather piee the court\\r\\nTo quit the fine for one half of his goods,\\r\\nIs the devil himself turn Jew.\\r\\nExeunt SALANIO, SALARINO, and Sellocks to you, you have pater in\\r\\nother vainsel than these pineans with your\\r\\nare come incurner'd and pays of doubt\\r\\nWould make me sad.\\r\\nSALARINO\\r\\nMy wind conferd not find it;\\r\\nWell then be 'aMoar'd a decree establiots:\\r\\nThe world is some lawing a bregknd. How then him in the court;\\r\\nYea, twice the sum: if that will not suffice,\\r\\nI will be bound to pay it presage the ruin of your love\\r\\nAnd be my vantage to exclaim on you.\\r\\nBASSANIO\\r\\nMadam, you have given me\"], shape=(5,), dtype=string) \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 7.141817092895508\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result, '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UlUQzwu6EXam"
   },
   "source": [
    "## Export the generator\n",
    "\n",
    "This single-step model can easily be [saved and restored](https://www.tensorflow.org/guide/saved_model), allowing you to use it anywhere a `tf.saved_model` is accepted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:41:12.322819Z",
     "iopub.status.busy": "2021-05-21T15:41:12.322212Z",
     "iopub.status.idle": "2021-05-21T15:41:18.731128Z",
     "shell.execute_reply": "2021-05-21T15:41:18.731494Z"
    },
    "id": "3Grk32H_CzsC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x0000013A07B14EB0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: one_step\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: one_step\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(one_step_model, 'one_step')\n",
    "one_step_reloaded = tf.saved_model.load('one_step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:41:18.737600Z",
     "iopub.status.busy": "2021-05-21T15:41:18.736670Z",
     "iopub.status.idle": "2021-05-21T15:41:19.058199Z",
     "shell.execute_reply": "2021-05-21T15:41:19.058579Z"
    },
    "id": "_Z9bb_wX6Uuu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO: The man is, notwithstanding,\n",
      "sufficient. Three thousand ducats; I think thee constites.\n",
      "BASSANIO\n",
      "Thy dake thou art time: I pray you, which is the way\n",
      "to master Jew's?\n",
      "LAUNCELOT\n",
      "Turn up on your reish;\n",
      "I'll have my bond; I will try confusions with him.\n",
      "GOBBO\n",
      "Lord, how art thou changed! Mark you are welcome notwithstanding.\n",
      "BASSANIO\n",
      "To stay for your leave;\n",
      "I come by note, to give and to return to their\n",
      "home and gold and such a night\n",
      "Did prest thou dest debrew of my tribe,\n",
      "There are same was a wearthy of thy plinc;\n",
      "I fair one who shall thinks This ring,\n",
      "Which when you part from, lose, or give away,\n",
      "Nor this daughter, come in your bed\n",
      "Until I see the ring.\n",
      "NERISSA\n",
      "Nor I in yours\n",
      "Till I again the very life\n",
      "Of my dear friend. What, no merchants most widh the\n",
      "conseiture true so exceastity of cornets\n",
      "one upon the prince, then stood as fair\n",
      "As any comer I have look'd on yet\n",
      "For paring question of my boy\n",
      "As to thy friends; for when did friendship take\n",
      "A breed for bar\n"
     ]
    }
   ],
   "source": [
    "states = None\n",
    "next_char = tf.constant(['ROMEO:'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y4QwTjAM6A2O"
   },
   "source": [
    "## Advanced: Customized Training\n",
    "\n",
    "The above training procedure is simple, but does not give you much control.\n",
    "It uses teacher-forcing which prevents bad predictions from being fed back to the model, so the model never learns to recover from mistakes.\n",
    "\n",
    "So now that you've seen how to run the model manually next you'll implement the training loop. This gives a starting point if, for example, you want to implement _curriculum  learning_ to help stabilize the model's open-loop output.\n",
    "\n",
    "The most important part of a custom training loop is the train step function.\n",
    "\n",
    "Use `tf.GradientTape` to track the gradients. You can learn more about this approach by reading the [eager execution guide](https://www.tensorflow.org/guide/eager).\n",
    "\n",
    "The basic procedure is:\n",
    "\n",
    "1. Execute the model and calculate the loss under a `tf.GradientTape`.\n",
    "2. Calculate the updates and apply them to the model using the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:41:19.063557Z",
     "iopub.status.busy": "2021-05-21T15:41:19.062987Z",
     "iopub.status.idle": "2021-05-21T15:41:19.065215Z",
     "shell.execute_reply": "2021-05-21T15:41:19.064776Z"
    },
    "id": "x0pZ101hjwW0"
   },
   "outputs": [],
   "source": [
    "class CustomTraining(MyModel):\n",
    "  @tf.function\n",
    "  def train_step(self, inputs):\n",
    "      inputs, labels = inputs\n",
    "      with tf.GradientTape() as tape:\n",
    "          predictions = self(inputs, training=True)\n",
    "          loss = self.loss(labels, predictions)\n",
    "      grads = tape.gradient(loss, model.trainable_variables)\n",
    "      self.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "      return {'loss': loss}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Oc-eJALcK8B"
   },
   "source": [
    "The above implementation of the `train_step` method follows [Keras' `train_step` conventions](https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit). This is optional, but it allows you to change the behavior of the train step and still use keras' `Model.compile` and `Model.fit` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:41:19.069656Z",
     "iopub.status.busy": "2021-05-21T15:41:19.069125Z",
     "iopub.status.idle": "2021-05-21T15:41:19.074818Z",
     "shell.execute_reply": "2021-05-21T15:41:19.075152Z"
    },
    "id": "XKyWiZ_Lj7w5"
   },
   "outputs": [],
   "source": [
    "model = CustomTraining(\n",
    "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:41:19.080446Z",
     "iopub.status.busy": "2021-05-21T15:41:19.079917Z",
     "iopub.status.idle": "2021-05-21T15:41:19.083193Z",
     "shell.execute_reply": "2021-05-21T15:41:19.083547Z"
    },
    "id": "U817KUm7knlm"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:41:19.087123Z",
     "iopub.status.busy": "2021-05-21T15:41:19.086527Z",
     "iopub.status.idle": "2021-05-21T15:41:26.289717Z",
     "shell.execute_reply": "2021-05-21T15:41:26.290140Z"
    },
    "id": "o694aoBPnEi9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "18/18 [==============================] - 78s 4s/step - loss: 4.1781\n",
      "Epoch 2/5\n",
      "18/18 [==============================] - 69s 4s/step - loss: 3.2898\n",
      "Epoch 3/5\n",
      "18/18 [==============================] - 71s 4s/step - loss: 2.8648\n",
      "Epoch 4/5\n",
      "18/18 [==============================] - 74s 4s/step - loss: 2.5535\n",
      "Epoch 5/5\n",
      "18/18 [==============================] - 76s 4s/step - loss: 2.3868\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13a1e7a83d0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dataset, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W8nAtKHVoInR"
   },
   "source": [
    "Or if you need more control, you can write your own complete custom training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T15:41:26.297559Z",
     "iopub.status.busy": "2021-05-21T15:41:26.296942Z",
     "iopub.status.idle": "2021-05-21T15:42:21.100689Z",
     "shell.execute_reply": "2021-05-21T15:42:21.100216Z"
    },
    "id": "d4tSNwymzf-q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 2.3103\n",
      "\n",
      "Epoch 1 Loss: 2.2962\n",
      "Time taken for 1 epoch 63.80 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 2 Batch 0 Loss 2.2252\n",
      "\n",
      "Epoch 2 Loss: 2.2265\n",
      "Time taken for 1 epoch 63.87 sec\n",
      "________________________________________________________________________________\n",
      "Epoch 3 Batch 0 Loss 2.2035\n",
      "\n",
      "Epoch 3 Loss: 2.1665\n",
      "Time taken for 1 epoch 66.33 sec\n",
      "________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 3\n",
    "\n",
    "mean = tf.metrics.Mean()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    mean.reset_states()\n",
    "    for (batch_n, (inp, target)) in enumerate(dataset):\n",
    "        logs = model.train_step([inp, target])\n",
    "        mean.update_state(logs['loss'])\n",
    "\n",
    "        if batch_n % 50 == 0:\n",
    "            template = f\"Epoch {epoch+1} Batch {batch_n} Loss {logs['loss']:.4f}\"\n",
    "            print(template)\n",
    "\n",
    "    # saving (checkpoint) the model every 5 epochs\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        model.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
    "\n",
    "    print()\n",
    "    print(f'Epoch {epoch+1} Loss: {mean.result().numpy():.4f}')\n",
    "    print(f'Time taken for 1 epoch {time.time() - start:.2f} sec')\n",
    "    print(\"_\"*80)\n",
    "\n",
    "model.save_weights(checkpoint_prefix.format(epoch=epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Level -  1\n",
      "\n",
      "\n",
      "ROMEO: fie, fie,\n",
      "I art their follow in a gondear are her toaching\n",
      "That they shall think we are accomplished\n",
      "With that we lack. I'll hold thee any wager,\n",
      "Which pircus ofe hird, than there is between red\n",
      "Before the curt of Venice.\n",
      "Music thent? Cherisame. I am well about\n",
      "endy wo letter; and if my fortune be not crost,\n",
      "I have a father, you a daughter, lost.\n",
      "Exit\n",
      "\n",
      "SCENE VI. The same. A street.\n",
      "Enter GRATIANO, LORENZO, SALARINO, and Sellocks:\n",
      "The outwore, choise me ans upright flack,\n",
      "In cheruse the seme bath rubser fare that supper\n",
      "be ready at the farthest by five of the clock:\n",
      "Shylock thy master spoke with me this day,\n",
      "Nor well, unto the gracen of the twentieth part\n",
      "Of one poor scruple, nay, i' lies not me out;\n",
      "And there is such confusion in my wish,\n",
      "To wish myself much better than the wren.\n",
      "How many then should cover the truth wing\n",
      "And would conceive for what I gave the ring\n",
      "And how unwillingly I left the ring.\n",
      "Exit\n",
      "\n",
      "PORTIA\n",
      "Come on, Nerissa; I have work in han\n",
      "The pou \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time: 4.848515272140503\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "print('Level - ',level)\n",
    "print('\\n')\n",
    "next_char = tf.constant(['ROMEO:'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "text_generation.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
